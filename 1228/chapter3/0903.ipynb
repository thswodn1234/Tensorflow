{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "MSE = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "train_data = np.array([ # t = 1*x1 + 2*x2 + 3\n",
        "#  x1, x2, t      \n",
        " [ 1,  0,  4],\n",
        " [ 2,  0,  5],\n",
        " [ 3,  0,  6],\n",
        " [ 4,  0,  7],\n",
        " [ 1,  1,  6],\n",
        " [ 2,  1,  7],\n",
        " [ 3,  1,  8],\n",
        " [ 4,  1,  9]], dtype=np.float32)\n",
        "\n",
        "X = train_data[:, :-1]\n",
        "t = train_data[:, -1:]\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "W = tf.Variable(tf.random.normal(shape=[2, 1]), )\n",
        "b = tf.Variable(tf.random.normal(shape=[1]))\n",
        "lr = 0.01   # learning rate, 0.001\n",
        "\n",
        "train_size = X.shape[0]\n",
        "batch_size = 4\n",
        "K = train_size// batch_size\n",
        "\n",
        "loss_list = [ ]\n",
        "for epoch in range(1000):\n",
        "    batch_loss = 0.0\n",
        "    for step in range(K):\n",
        "        mask = np.random.choice(train_size, batch_size)\n",
        "        x_batch = X[mask]\n",
        "        t_batch = t[mask]\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            y = tf.matmul(x_batch, W) + b\n",
        "            loss = MSE(y, t_batch)\n",
        "            \n",
        "        batch_loss += loss.numpy()\n",
        "        \n",
        "        dW, dB = tape.gradient(loss, [W, b])\n",
        "        W.assign_sub(lr * dW)\n",
        "        b.assign_sub(lr * dB)\n",
        "        \n",
        "    batch_loss /= K    \n",
        "    loss_list.append(batch_loss) # average loss    \n",
        "##    if not epoch%100:\n",
        "##            print(\"epoch={}, batch_loss={}\".format(epoch, batch_loss))\n",
        "\n",
        "print(\"W={}. b={}, loss={}\".format(W.numpy(), b.numpy(), batch_loss))\n",
        "\n",
        "plt.plot(loss_list)\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}