{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers   import Input, Conv2D, MaxPool2D, Dense  \n",
        "from tensorflow.keras.layers   import BatchNormalization, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#1: \n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "\n",
        "#2\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') # (50000, 32, 32, 3)\n",
        "x_test  = x_test.astype('float32')  # (10000, 32, 32, 3)\n",
        "\n",
        "# one-hot encoding \n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "#3: build a model with functional API\n",
        "def create_cnn2d(input_shape, num_class = 10):\n",
        "    inputs = Input(shape=input_shape) #  shape=(32, 32, 3)\n",
        "    x=Conv2D(filters=16, kernel_size = (3,3), activation='relu')(inputs)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=MaxPool2D()(x)\n",
        "\n",
        "    x=Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
        "    x=MaxPool2D()(x)\n",
        "    x=Dropout(rate=0.2)(x)\n",
        "      \n",
        "    x=Flatten()(x)\n",
        "    outputs= Dense(units=num_class, activation='softmax')(x)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    \n",
        "    opt = RMSprop(learning_rate=0.001)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = create_cnn2d(input_shape = x_train.shape[1:])\n",
        "model.summary()\n",
        "\n",
        "#4: image augmentation\n",
        "#4-1:\n",
        "datagen = ImageDataGenerator( # ref: https://keras.io/ko/preprocessing/image/\n",
        "    featurewise_center = True,            # mean = 0.0\n",
        "    featurewise_std_normalization= True,  # std = 1.0\n",
        "    rotation_range=10,    \n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2)\n",
        "\n",
        "datagen.fit(x_train) #  computes the internal data stats: mean, std, zca\n",
        "print(\"datagen.mean = \", datagen.mean)\n",
        "print(\"datagen.std = \",  datagen.std)\n",
        "\n",
        "#4-2: split train into (train, valid): n_valid \n",
        "n_valid = 5000\n",
        "x_valid = x_train[-n_valid:]\n",
        "y_valid = y_train[-n_valid:]\n",
        "x_train = x_train[:-n_valid]\n",
        "y_train = y_train[:-n_valid]\n",
        "\n",
        "#4-3: ref: https://www.tensorflow.org/guide/keras/custom_callback\n",
        "class MyCustomCallback(tf.keras.callbacks.Callback):           \n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        print(\"batch {} ends, loss:{:.2f}, acc:{:.2f}\".format(\n",
        "            batch, logs['loss'],  logs['accuracy']))   \n",
        "\n",
        "#5: train the model using generator\n",
        "datagen.standardize(x_valid) # normalize x_valid, the same as datagen\n",
        "train_generator= datagen.flow(x=x_train, y=y_train , batch_size=400)\n",
        "train_steps= int(np.ceil(train_generator.n/train_generator.batch_size))\n",
        "print(\"train_steps=\", train_steps) # 113\n",
        "\n",
        "ret = model.fit(train_generator, epochs=100,\n",
        "                validation_data=(x_valid, y_valid), verbose=0,\n",
        "                steps_per_epoch= train_steps) \n",
        "                ##,callbacks=[MyCustomCallback()])\n",
        "\n",
        "#6:  predict and evaluate the model\n",
        "#6-1: normalize x_train, x_test, the same as datagen\n",
        "datagen.standardize(x_train) # mean=0, std=1\n",
        "datagen.standardize(x_test)  # mean=0, std=1\n",
        "\n",
        "#6-2: calculate confusion_matrix(C)\n",
        "y_pred = model.predict(x_train)\n",
        "y_label = np.argmax(y_pred, axis = 1)\n",
        "C = tf.math.confusion_matrix(np.argmax(y_train, axis = 1), y_label)\n",
        "##print(\"confusion_matrix(C):\", C)\n",
        "\n",
        "#6-3: evaluate\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train, verbose=2)\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "#7: plot accuracy and loss\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 6))\n",
        "ax[0].plot(ret.history['loss'],  \"g-\")\n",
        "ax[0].set_title(\"train loss\")\n",
        "ax[0].set_xlabel('epochs')\n",
        "ax[0].set_ylabel('loss')\n",
        "\n",
        "ax[1].plot(ret.history['accuracy'],     \"b-\", label=\"train accuracy\")\n",
        "ax[1].plot(ret.history['val_accuracy'], \"r-\", label=\"val_accuracy\")\n",
        "ax[1].set_title(\"accuracy\")\n",
        "ax[1].set_xlabel('epochs')\n",
        "ax[1].set_ylabel('accuracy')\n",
        "plt.legend(loc=\"best\")\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}