{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.layers   import Input, Conv2D, MaxPool2D, Dense  \n",
        "from tensorflow.keras.layers   import BatchNormalization, Dropout\n",
        "from tensorflow.keras.layers   import Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#1: \n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "\n",
        "#2\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data() # 'fine'\n",
        "x_train = x_train.astype('float32') # (50000, 32, 32, 3)\n",
        "x_test  = x_test.astype('float32')  # (10000, 32, 32, 3)\n",
        "\n",
        "# one-hot encoding \n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test  = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "# preprocessing, 'caffe', x_train, x_test: BGR\n",
        "x_train = preprocess_input(x_train)\n",
        "x_test  = preprocess_input(x_test)\n",
        "\n",
        "#3: build VGG modelfor CIFAR-100\n",
        "#3-1: resize_layer\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "resize_layer = tf.keras.layers.Lambda( \n",
        "                             lambda img: tf.image.resize(img,(224, 224)))(inputs) \n",
        "\n",
        "#3-2:\n",
        "vgg_model = VGG16(weights='imagenet', include_top= False, \n",
        "                     input_tensor= resize_layer) # input_tensor= inputs\n",
        "vgg_model.trainable=False\n",
        "                      \n",
        "#3-3: output: classification\n",
        "x = vgg_model.output\n",
        "##x = Flatten()(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(rate=0.5)(x)\n",
        "outs  = Dense(100, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outs)\n",
        "##model.summary()\n",
        "\n",
        "#4: image augmentation\n",
        "datagen = ImageDataGenerator( # ref: https://keras.io/ko/preprocessing/image/\n",
        "    rotation_range=10,    \n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    validation_split=0.2)\n",
        "\n",
        "train_generator= datagen.flow(x=x_train, y=y_train, batch_size=16, subset='training')\n",
        "valid_generator= datagen.flow(x=x_train, y=y_train, batch_size=16, subset='validation')\n",
        "\n",
        "train_steps= int(np.ceil(train_generator.n/train_generator.batch_size))\n",
        "valid_steps= int(np.ceil(valid_generator.n/valid_generator.batch_size))\n",
        "print(\"train_steps=\", train_steps)\n",
        "print(\"valid_steps=\", valid_steps)\n",
        "\n",
        "#5: train the model using generator\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.0001)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "ret = model.fit(train_generator, epochs=30,\n",
        "                validation_data=valid_generator,\n",
        "                steps_per_epoch= train_steps,\n",
        "                validation_steps= valid_steps,\n",
        "                verbose=0)\n",
        "\n",
        "#6:  predict and evaluate the model\n",
        "#6-1: calculate confusion_matrix(C)\n",
        "y_pred = model.predict(x_train)\n",
        "y_label = np.argmax(y_pred, axis = 1)\n",
        "C = tf.math.confusion_matrix(np.argmax(y_train, axis = 1), y_label)\n",
        "##print(\"confusion_matrix(C):\", C)\n",
        "\n",
        "#6-3: evaluate\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train, verbose=2)\n",
        "test_loss, test_acc   = model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "#7: plot accuracy and loss\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 6))\n",
        "ax[0].plot(ret.history['loss'],  \"g-\")\n",
        "ax[0].set_title(\"train loss\")\n",
        "ax[0].set_xlabel('epochs')\n",
        "ax[0].set_ylabel('loss')\n",
        "\n",
        "ax[1].plot(ret.history['accuracy'],     \"b-\", label=\"train accuracy\")\n",
        "ax[1].plot(ret.history['val_accuracy'], \"r-\", label=\"val_accuracy\")\n",
        "ax[1].set_title(\"accuracy\")\n",
        "ax[1].set_xlabel('epochs')\n",
        "ax[1].set_ylabel('accuracy')\n",
        "plt.legend(loc=\"best\")\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}